{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f678288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17eed354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  instance_id                                         sentence_1  \\\n",
      "0  train_id_0  Is it in the food supply ? \" says David Ropeik...   \n",
      "1  train_id_1  Hundreds of soldiers were involved , an appare...   \n",
      "2  train_id_2  And Sen. Michael Crapo , R-Idaho , chairman of...   \n",
      "3  train_id_3  The gunman , 26-year-old Harold Kilpatrick jnr...   \n",
      "4  train_id_4  The League of United Latin American Citizens ,...   \n",
      "\n",
      "                                          sentence_2 gold_label  Unnamed: 4  \n",
      "0  The pound also made progress against the dolla...          0         NaN  \n",
      "1  Avants , wearing a light brown jumpsuit , had ...          0         NaN  \n",
      "2  . 's Kempthorne of friend longtime a is , nomi...          0         NaN  \n",
      "3   In fact , I was physically sick several times...          0         NaN  \n",
      "4  No. 2 HP saw its Unix server sales dropped 3.6...          0         NaN  \n",
      "  instance_id                                         sentence_1  \\\n",
      "0    dev_id_0  He said he did not think that the Shenzhou V l...   \n",
      "1    dev_id_1  Under NASD regulations , Mr. Young can file a ...   \n",
      "2    dev_id_2  In Europe , France 's CAC-40 rose 0.6 percent ...   \n",
      "3    dev_id_3  Schroeder cancelled his Italian holiday after ...   \n",
      "4    dev_id_4  U.S. District Judge William Barbour said he im...   \n",
      "\n",
      "                                          sentence_2 gold_label Unnamed: 4  \\\n",
      "0  He said he did not think that the Shenzhou V l...          0        NaN   \n",
      "1  Josephine Burke , who ran the unlicensed dayca...          0        NaN   \n",
      "2  IBM shares closed up $ 1.75 , or 2.11 percent ...          0        NaN   \n",
      "3  Schroeder cancelled his Italian holiday after ...          0        NaN   \n",
      "4  Federal Judge William Barbour said Tuesday he ...          1        NaN   \n",
      "\n",
      "   Unnamed: 5  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n"
     ]
    }
   ],
   "source": [
    "#nltk tooks for text preprocessing\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "#load data and check for missing values\n",
    "\n",
    "df_train=pd.read_csv('train_with_label.csv')\n",
    "print(df_train.head())\n",
    "\n",
    "df_dev=pd.read_csv('dev_with_label.csv')\n",
    "print(df_dev.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb7432fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  instance_id                                         sentence_1  \\\n",
      "0    dev_id_0  He said he did not think that the Shenzhou V l...   \n",
      "1    dev_id_1  Under NASD regulations , Mr. Young can file a ...   \n",
      "2    dev_id_2  In Europe , France 's CAC-40 rose 0.6 percent ...   \n",
      "3    dev_id_3  Schroeder cancelled his Italian holiday after ...   \n",
      "4    dev_id_4  U.S. District Judge William Barbour said he im...   \n",
      "\n",
      "                                          sentence_2 gold_label Unnamed: 4  \\\n",
      "0  He said he did not think that the Shenzhou V l...          0        NaN   \n",
      "1  Josephine Burke , who ran the unlicensed dayca...          0        NaN   \n",
      "2  IBM shares closed up $ 1.75 , or 2.11 percent ...          0        NaN   \n",
      "3  Schroeder cancelled his Italian holiday after ...          0        NaN   \n",
      "4  Federal Judge William Barbour said Tuesday he ...          1        NaN   \n",
      "\n",
      "   Unnamed: 5                                        sent1_clean  \\\n",
      "0         NaN  he said think shenzhou v launch militari appli...   \n",
      "1         NaN  under nasd regul mr young file respons request...   \n",
      "2         NaN  in europ franc cac 40 rose 0 6 percent britain...   \n",
      "3         NaN  schroeder cancel italian holiday stefani refus...   \n",
      "4         NaN  u s district judg william barbour said impos m...   \n",
      "\n",
      "                                         sent2_clean  \n",
      "0  he said think shenzhou v launch militari appli...  \n",
      "1  josephin burk ran unlicens daycar eventu serv ...  \n",
      "2  ibm share close 1 75 2 11 percent 84 50 new yo...  \n",
      "3  schroeder cancel italian holiday stefani refus...  \n",
      "4  feder judg william barbour said tuesday impos ...  \n",
      "(3809, 8)\n"
     ]
    }
   ],
   "source": [
    "#text cleaning function for punction and stopwords, then join and space words\n",
    "\n",
    "def clean_text(txt):\n",
    "    text = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    tokens = re.split('\\W+', txt)\n",
    "    txt = \" \".join([ps.stem(word) for word in tokens if word not in stopwords])\n",
    "    return txt\n",
    "\n",
    "#create two new features with clean sentence data\n",
    "\n",
    "df_train['sent1_clean'] = df_train['sentence_1'].apply(lambda x: clean_text(x))\n",
    "df_train['sent2_clean'] = df_train['sentence_2'].apply(lambda x: clean_text(x))\n",
    "\n",
    "#repeat for dev set\n",
    "df_dev['sent1_clean'] = df_dev['sentence_1'].apply(lambda x: clean_text(x))\n",
    "df_dev['sent2_clean'] = df_dev['sentence_2'].apply(lambda x: clean_text(x))\n",
    "print(df_dev.head())\n",
    "print(df_dev.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80fda207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      00  000  0001  007  01  011  012  015  018  019  ...  zuccarini  \\\n",
      "0      0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "1      0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "2      0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "3      0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "4      0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "...   ..  ...   ...  ...  ..  ...  ...  ...  ...  ...  ...        ...   \n",
      "7573   0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "7574   0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "7575   1    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "7576   0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "7577   0    0     0    0   0    0    0    0    0    0  ...          0   \n",
      "\n",
      "      zulfiqar  zvonareva  µguru  äì  äî  äò  äô  äù  äú  \n",
      "0            0          0      0   0   0   0   0   0   0  \n",
      "1            0          0      0   0   0   0   0   0   0  \n",
      "2            0          0      0   0   0   0   0   0   0  \n",
      "3            0          0      0   0   0   0   0   0   0  \n",
      "4            0          0      0   0   0   0   0   0   0  \n",
      "...        ...        ...    ...  ..  ..  ..  ..  ..  ..  \n",
      "7573         0          0      0   0   0   0   0   0   0  \n",
      "7574         0          0      0   0   0   0   0   0   0  \n",
      "7575         0          0      0   0   0   0   0   0   0  \n",
      "7576         0          0      0   0   0   0   0   0   0  \n",
      "7577         0          0      0   0   0   0   0   0   0  \n",
      "\n",
      "[7578 rows x 8852 columns]\n",
      "      00  000  007  01  011  012  015  018  019  02  ...  zookeep  zuccarini  \\\n",
      "0      0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "1      0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "2      0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "3      0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "4      0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "...   ..  ...  ...  ..  ...  ...  ...  ...  ...  ..  ...      ...        ...   \n",
      "7573   0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "7574   0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "7575   1    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "7576   0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "7577   0    0    0   0    0    0    0    0    0   0  ...        0          0   \n",
      "\n",
      "      zulifquar  zvonareva  äì  äî  äò  äô  äù  äú  \n",
      "0             0          0   0   0   0   0   0   0  \n",
      "1             0          0   0   0   0   0   0   0  \n",
      "2             0          0   0   0   0   0   0   0  \n",
      "3             0          0   0   0   0   0   0   0  \n",
      "4             0          0   0   0   0   0   0   0  \n",
      "...         ...        ...  ..  ..  ..  ..  ..  ..  \n",
      "7573          0          0   0   0   0   0   0   0  \n",
      "7574          0          0   0   0   0   0   0   0  \n",
      "7575          0          0   0   0   0   0   0   0  \n",
      "7576          0          0   0   0   0   0   0   0  \n",
      "7577          0          0   0   0   0   0   0   0  \n",
      "\n",
      "[7578 rows x 9352 columns]\n"
     ]
    }
   ],
   "source": [
    "#use count vectorizer to search for unigrams\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv1 = CountVectorizer()\n",
    "\n",
    "bag_of_words_trainsent1 = cv.fit_transform(df_train['sent1_clean'])\n",
    "bag_of_words_trainsent1 = pd.DataFrame(bag_of_words_trainsent1.toarray(),\n",
    "                            columns = cv.get_feature_names())\n",
    "print(bag_of_words_trainsent1)\n",
    "\n",
    "bag_of_words_trainsent2 = cv1.fit_transform(df_train['sent2_clean'])\n",
    "bag_of_words_trainsent2 = pd.DataFrame(bag_of_words_trainsent2.toarray(),\n",
    "                            columns = cv1.get_feature_names())\n",
    "print(bag_of_words_trainsent2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2ea7121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      00  000  007  01  010  012  015  018  02  03  ...  zivkov  zone  \\\n",
      "0      0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "1      0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "2      0    0    0   0    0    0    0    0   1   0  ...       0     0   \n",
      "3      0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "4      0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "...   ..  ...  ...  ..  ...  ...  ...  ...  ..  ..  ...     ...   ...   \n",
      "3804   0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "3805   0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "3806   0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "3807   0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "3808   0    0    0   0    0    0    0    0   0   0  ...       0     0   \n",
      "\n",
      "      zuccarini  zvonareva  äì  äî  äò  äô  äù  äú  \n",
      "0             0          0   0   0   0   0   0   0  \n",
      "1             0          0   0   0   0   0   0   0  \n",
      "2             0          0   0   0   0   0   0   0  \n",
      "3             0          0   0   0   0   0   0   0  \n",
      "4             0          0   0   0   0   0   0   0  \n",
      "...         ...        ...  ..  ..  ..  ..  ..  ..  \n",
      "3804          0          0   0   0   0   0   0   0  \n",
      "3805          0          0   0   0   0   0   0   0  \n",
      "3806          0          0   0   0   0   0   0   0  \n",
      "3807          0          0   0   0   0   0   0   0  \n",
      "3808          0          0   0   0   0   0   0   0  \n",
      "\n",
      "[3809 rows x 7182 columns]\n",
      "      00  000  002  007  01  012  015  018  02  020  ...  zimbabw  zivkov  \\\n",
      "0      0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "1      0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "2      0    0    0    0   0    0    0    0   1    0  ...        0       0   \n",
      "3      0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "4      0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "...   ..  ...  ...  ...  ..  ...  ...  ...  ..  ...  ...      ...     ...   \n",
      "3804   0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "3805   0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "3806   0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "3807   0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "3808   0    0    0    0   0    0    0    0   0    0  ...        0       0   \n",
      "\n",
      "      zone  zuccarini  zvonareva  äì  äî  äô  äù  äú  \n",
      "0        0          0          0   0   0   0   0   0  \n",
      "1        0          0          0   0   0   0   0   0  \n",
      "2        0          0          0   0   0   0   0   0  \n",
      "3        0          0          0   0   0   0   0   0  \n",
      "4        0          0          0   0   0   0   0   0  \n",
      "...    ...        ...        ...  ..  ..  ..  ..  ..  \n",
      "3804     0          0          0   0   0   0   0   0  \n",
      "3805     0          0          0   0   0   0   0   0  \n",
      "3806     0          0          0   0   0   0   0   0  \n",
      "3807     0          0          0   0   0   0   0   0  \n",
      "3808     0          0          0   0   0   0   0   0  \n",
      "\n",
      "[3809 rows x 7887 columns]\n"
     ]
    }
   ],
   "source": [
    "#use count vectorizer to search for unigrams for dev set\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv1 = CountVectorizer()\n",
    "\n",
    "bag_of_words_devsent1 = cv.fit_transform(df_dev['sent1_clean'])\n",
    "bag_of_words_devsent1 = pd.DataFrame(bag_of_words_devsent1.toarray(),\n",
    "                            columns = cv.get_feature_names())\n",
    "print(bag_of_words_devsent1)\n",
    "\n",
    "bag_of_words_devsent2 = cv1.fit_transform(df_dev['sent2_clean'])\n",
    "bag_of_words_devsent2 = pd.DataFrame(bag_of_words_devsent2.toarray(),\n",
    "                            columns = cv1.get_feature_names())\n",
    "print(bag_of_words_devsent2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ae085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.merge(bag_of_words_trainsent1, bag_of_words_trainsent2)\n",
    "dev_full = pd.merge(bag_of_words_devsent1, bag_of_words_devsent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81c51264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (1.11.0)\n",
      "Requirement already satisfied: torchvision in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: requests in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/praneeltrivedy/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision   # install pytorch\n",
    "!/opt/bin/nvidia-smi  #show GPU \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07202e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "args['batch_size']=100\n",
    "args['test_batch_size']=100\n",
    "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
    "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
    "args['log_interval']=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an mlp\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 256)   # linear layer (784 -> 256)\n",
    "        self.fc2 = nn.Linear(256,128)  # linear layer (256 -> 128)\n",
    "        self.fc3 = nn.Linear(128,10)  # linear layer (128 -> 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = x.view(-1,28*28) #input layer\n",
    "        h1 = F.relu(self.fc1(h0)) # hidden layer 1\n",
    "        h2 = F.relu(self.fc2(h1)) # hidden layer 2\n",
    "        h3 = self.fc3(h2) # output layer\n",
    "\n",
    "        return h3\n",
    "\n",
    "model = Net()\n",
    "model.cuda() # put the model on GPU\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = args['lr'])\n",
    "\n",
    "#load the data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    return 100. * correct.item() / len(test_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cf80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = []\n",
    "epochs = []\n",
    "Training_Loss = []\n",
    "Testing_Accuracy = []\n",
    "\n",
    "for epoch in range(1, args['epochs'] + 1):\n",
    "  model.train()\n",
    "    \n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        Training_Loss.append(loss.item())\n",
    "        \n",
    "        \n",
    "\n",
    "        # compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "\n",
    "        #Print out the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "\n",
    "           \n",
    "\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    \n",
    "  Testing_Epoch_Accuracy = test()\n",
    "  Testing_Accuracy.append(Testing_Epoch_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a9049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
